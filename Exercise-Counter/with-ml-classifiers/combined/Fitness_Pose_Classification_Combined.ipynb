{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-qOB5mqXUgC"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml7mb7xPYIEw"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.19.3\n",
        "!pip install opencv-python==4.5.1.48\n",
        "!pip install tqdm==4.56.0\n",
        "!pip install mediapipe==0.8.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RofM18ra4B7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIydJ61vXXFR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "!pip install mediapipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show mediapipe"
      ],
      "metadata": {
        "id": "0a_RfR9zYtDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7zVJWKoW5kL"
      },
      "source": [
        "##Pipeline to preprocess the images to feature vectors containing the landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnbuch4KZZBW"
      },
      "source": [
        "Locally create a folder named `fitness_poses_images_in` with image samples.\n",
        "\n",
        "Images should repesent terminal states of desired pose classes. I.e. if you want to classify push-up provide iamges for two classes: when person is up, and when person is down.\n",
        "\n",
        "There should be about a few hundred samples per class covering different camera angles, environment conditions, body shapes, and exercise variations to build a good classifier.\n",
        "\n",
        "Required structure of the images_in_folder:\n",
        "```\n",
        "fitness_poses_images_in/\n",
        "  pushups_up/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  pushups_down/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  ...\n",
        "```\n",
        "\n",
        "Zip the `fitness_poses_images_in` folder:\n",
        "```\n",
        "zip -r fitness_poses_images_in.zip fitness_poses_images_in\n",
        "```\n",
        "\n",
        "And run the code below to upload it to the Colab runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjkEaNsVYRYA"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "uploaded = files.upload()\n",
        "os.listdir('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11KJwFXmZQ_h"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "zf = zipfile.ZipFile(\"/content/drive/MyDrive/fitness_poses_images_in.zip\")\n",
        "zf.extractall()\n",
        "os.listdir('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_IxEU3YbaUv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "from mediapipe.python.solutions import pose as mp_pose\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-xDQAuIZOOX"
      },
      "outputs": [],
      "source": [
        "# Folder with images to use as target poses for classification.\n",
        "#\n",
        "# Images should repesent terminal states of desired pose classes. I.e. if you\n",
        "# want to classify push-up provide iamges for two classes: when person is up,\n",
        "# and when person is down.\n",
        "#\n",
        "# Required structure of the images_in_folder:\n",
        "#   fitness_poses_images_in/\n",
        "#     pushups_up/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     pushups_down/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     ...\n",
        "images_in_folder = 'fitness_pose_images_in'\n",
        "\n",
        "# Output folders for bootstrapped images and CSVs. Image will have a predicted\n",
        "# Pose rendering and can be used to remove unwanted samples.\n",
        "images_out_folder = 'fitness_pose_images_out'\n",
        "\n",
        "# Output CSV path to put bootstrapped poses to. This CSV will be used by the\n",
        "# demo App.\n",
        "#\n",
        "# Output CSV format:\n",
        "#   sample_00001,pose_class_1,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
        "#   sample_00002,pose_class_2,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
        "#   ...\n",
        "#\n",
        "csv_out_path = 'fitness_pose.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4w663rcZe6K"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open(csv_out_path, 'w') as csv_out_file:\n",
        "  csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "  # Folder names are used as pose class names.\n",
        "  pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "\n",
        "  for pose_class_name in pose_class_names:\n",
        "    print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "    if not os.path.exists(os.path.join(images_out_folder, pose_class_name)):\n",
        "      os.makedirs(os.path.join(images_out_folder, pose_class_name))\n",
        "\n",
        "    image_names = sorted([\n",
        "        n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
        "        if not n.startswith('.')])\n",
        "    for image_name in tqdm.tqdm(image_names, position=0):\n",
        "      try:\n",
        "        \n",
        "      # Load image.\n",
        "        input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
        "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "      except:\n",
        "        continue\n",
        "      \n",
        "      # Initialize fresh pose tracker and run it.\n",
        "      with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
        "        result = pose_tracker.process(image=input_frame)\n",
        "        pose_landmarks = result.pose_landmarks\n",
        "      \n",
        "      # Save image with pose prediction (if pose was detected).\n",
        "      output_frame = input_frame.copy()\n",
        "      if pose_landmarks is not None:\n",
        "        mp_drawing.draw_landmarks(image=output_frame, landmark_list=pose_landmarks, connections=mp_pose.POSE_CONNECTIONS)\n",
        "      output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
        "      cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
        "      \n",
        "      # Save landmarks.\n",
        "      if pose_landmarks is not None:\n",
        "        # Check the number of landmarks and take pose landmarks.\n",
        "        assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "        pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "        # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "        # correct aspect ratio.\n",
        "        frame_height, frame_width = output_frame.shape[:2]\n",
        "        pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "        # Write pose sample to CSV.\n",
        "        pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
        "        csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPlsxareW5yH"
      },
      "source": [
        "##kNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "o6ozIT5XIFiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "gsSKyQo6I9pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fitness_pose.csv')\n",
        "y = df['Y']\n",
        "X = df.drop(['Image_name', 'Y'], axis = 1)\n",
        "classes = {\"Y\": {\"bicep_curls_down\": 0, \"bicep_curls_up\": 2, \"Both_Hands_Down\": 2, \"Both_Hands_Up\": 3, \"Middle\": 4, \"One_Hand_Up\": 5, \"Squatting\": 6, \"Standing\": 7 }}\n",
        "df = df.replace(classes) \n",
        "df.head()\n",
        "y = df['Y']"
      ],
      "metadata": {
        "id": "A6LQPYba1_SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HTLU7gejghh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LlaiSBwdL-N"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, y, test_size = 1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "x_train_standardized = sc_X.fit_transform(X_train)\n",
        "x_test_standardized = sc_X.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.values\n"
      ],
      "metadata": {
        "id": "oChjgrIwW49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_test)"
      ],
      "metadata": {
        "id": "TMfhiH7ne1ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_jobs=-1)\n",
        "knn_params = {'n_neighbors': [3,4,5,6,7,8,9,10,15,20],\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              }\n",
        "knn_clf = GridSearchCV(knn,knn_params)\n",
        "print('====> Fitting for SVC model....')\n",
        "knn_clf.fit(x_train_standardized, y_train)\n",
        "knn_results = pd.DataFrame(knn_clf.cv_results_)   \n",
        "knn_results           "
      ],
      "metadata": {
        "id": "Fz0AiC_gyJ-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_clf.best_params_"
      ],
      "metadata": {
        "id": "LbzTSeB2M9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_pred = knn_clf.predict(x_test_standardized)"
      ],
      "metadata": {
        "id": "o5kpjLcBXzdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = [\"bicep_curls_down\", \"bicep_curls_up\", \"Both_Hands_Down\", \"Both_Hands_Up\", \"Middle\", \"One_Hand_Up\", \"Squatting\", \"Standing\"] "
      ],
      "metadata": {
        "id": "vxyWoxVajT9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = scaler.transform(X)\n",
        "prediction = model.predict(X)\n"
      ],
      "metadata": {
        "id": "rQHxMe0-HfAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y, prediction))\n",
        "print(f\"The knn model is {accuracy_score(prediction,y)*100}% accurate\")\n",
        "print(\"Confusion Matrix\")\n",
        "confusion_matrix(prediction,y)"
      ],
      "metadata": {
        "id": "-joopmFkVVSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_KNrA_Sd25V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z2EaM4A625ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caqo--aJSJQd"
      },
      "outputs": [],
      "source": [
        "def ExtractFromImage(path):\n",
        "    image = cv2.imread(path)\n",
        "    with mp_pose.Pose() as pose:\n",
        "        result = pose.process(image)\n",
        "        pose_landmarks = result.pose_landmarks\n",
        "        if pose_landmarks is not None:\n",
        "        # Check the number of landmarks and take pose landmarks.\n",
        "            assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "            # correct aspect ratio.\n",
        "            frame_height, frame_width = output_frame.shape[:2]\n",
        "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "            h = []\n",
        "            pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(str).tolist()\n",
        "            h.append(pose_landmarks)   \n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dn2rsjcp2z2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TprJB7U6QSrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fitness_Pose_Classification_Combined.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}