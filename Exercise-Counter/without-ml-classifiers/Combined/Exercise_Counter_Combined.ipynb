{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combined_Bonus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrzInFWXrx8o",
        "outputId": "6f45c86b-2d68-46ed-a9dc-8de6c40563ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.0.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "C4eN_gWKsVrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_angle(a,b,c): # 3D points\n",
        "    ''' Arguments:\n",
        "        a,b,c -- Values (x,y,z, visibility) of the three points a, b and c which will be used to calculate the\n",
        "                vectors ab and bc where 'b' will be 'elbow', 'a' will be shoulder and 'c' will be wrist.\n",
        "        \n",
        "        Returns:\n",
        "        theta : Angle in degress between the lines joined by coordinates (a,b) and (b,c)\n",
        "    '''\n",
        "    a = np.array([a.x, a.y])#, a.z])    # Reduce 3D point to 2D\n",
        "    b = np.array([b.x, b.y])#, b.z])    # Reduce 3D point to 2D\n",
        "    c = np.array([c.x, c.y])#, c.z])    # Reduce 3D point to 2D\n",
        "\n",
        "    ab = np.subtract(a, b)\n",
        "    bc = np.subtract(b, c)\n",
        "    \n",
        "    theta = np.arccos(np.dot(ab, bc) / np.multiply(np.linalg.norm(ab), np.linalg.norm(bc)))     # A.B = |A||B|cos(x) where x is the angle b/w A and B\n",
        "    theta = 180 - 180 * theta / 3.14    # Convert radians to degrees\n",
        "    return np.round(theta, 2)"
      ],
      "metadata": {
        "id": "UB9CvlWBsVtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(a, b):\n",
        "    a = np.array([a.x, a.y])#, a.z])    # Reduce 3D point to 2D\n",
        "    b = np.array([b.x, b.y])#, b.z])    # Reduce 3D point to 2D\n",
        "\n",
        "    ab = np.subtract(a, b)\n",
        "\n",
        "    return np.linalg.norm(ab)\n",
        "\n"
      ],
      "metadata": {
        "id": "uj5aSoizsVvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAngleBetweenVectors(v1, v2):\n",
        "    v1 = v1/ np.linalg.norm(v1)\n",
        "    v2 = v2/ np.linalg.norm(v2)\n",
        "\n",
        "    return np.degrees(np.arccos(np.dot(v1, v2)))"
      ],
      "metadata": {
        "id": "RBOdafafvIZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLegAngle(leg_landmarks):\n",
        "    v1 = np.array([\n",
        "            (leg_landmarks[0].x - leg_landmarks[1].x),\n",
        "            (leg_landmarks[0].y - leg_landmarks[1].y),\n",
        "            (leg_landmarks[0].z - leg_landmarks[1].z)])\n",
        "              \n",
        "    v2 = np.array([\n",
        "            (leg_landmarks[2].x - leg_landmarks[1].x),\n",
        "            (leg_landmarks[2].y - leg_landmarks[1].y),\n",
        "            (leg_landmarks[2].z - leg_landmarks[1].z)])\n",
        "              \n",
        "    return getAngleBetweenVectors(v1, v2)"
      ],
      "metadata": {
        "id": "mNo2fZ4tvIcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "counter_both_hands = 0\n",
        "counter_one_hand = 0\n",
        "counter_squats = 0\n",
        "counter_bicep_curl = 0\n",
        "\n",
        "flag_both_hands = None\n",
        "flag_bicep_curl = None\n",
        "\n",
        "b1 = False\n",
        "b2 = False\n",
        "\n",
        "position = 0\n",
        "state = 0\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/ninad.mp4\")\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#print(fps)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "with mp_pose.Pose(\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as pose:\n",
        "  while cap.isOpened():\n",
        "    success, image = cap.read()\n",
        "    if not success:\n",
        "      print(\"Ignoring empty camera frame.\")\n",
        "      # If loading a video, use 'break' instead of 'continue'.\n",
        "      break\n",
        "\n",
        "    # To improve performance, optionally mark the image as not writeable to\n",
        "    # pass by reference.\n",
        "    image.flags.writeable = False\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = pose.process(image)\n",
        "\n",
        "    # Draw the pose annotation on the image.\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    mp_drawing.draw_landmarks(\n",
        "        image,\n",
        "        results.pose_landmarks,\n",
        "    )\n",
        "    # Flip the image horizontally for a selfie-view display.\n",
        "    #image=cv2.resize(image,(1080,720))\n",
        "    #cv2_imshow(image)\n",
        "\n",
        "    landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]\n",
        "    left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
        "\n",
        "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "    right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
        "    right_elbow = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW]\n",
        "\n",
        "    d_left1 = distance(left_hip, left_elbow)\n",
        "    d_right1 = distance(right_hip, right_elbow)\n",
        "\n",
        "    d_left2 = distance(left_shoulder, left_hip)\n",
        "    d_right2 = distance(right_shoulder, right_hip)\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "    if d_left1 > d_left2 + 0.05 and d_right1 > d_right2 + 0.05:\n",
        "        flag_both_hands = 'up'\n",
        "    if d_left1 + 0.05 < d_left2 and d_right1 + 0.05 < d_right2 and flag_both_hands == 'up':\n",
        "        counter_both_hands += 1\n",
        "        flag_both_hands = 'down'\n",
        "\n",
        "    ##############################################################################\n",
        "\n",
        "    theta = calc_angle(right_shoulder, right_elbow, right_wrist)\n",
        "\n",
        "    if theta > 160:\n",
        "      flag_bicep_curl = 'down'\n",
        "      if theta < 80 and flag_bicep_curl == 'down':\n",
        "          counter_bicep_curl += 1\n",
        "          flag_bicep_curl = 'up'\n",
        "\n",
        "    ###############################################################################\n",
        "\n",
        "    image_height, image_width, _ = image.shape\n",
        "\n",
        "    left_index_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_INDEX].y * image_height\n",
        "    left_pinky_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_PINKY].y * image_height\n",
        "    left_thumb_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_THUMB].y * image_height\n",
        "    left_wrist_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST].y * image_height\n",
        "    left_elbow_y = results.pose_landmarks.landmark[13].y * image_height\n",
        "    left_hip_y = results.pose_landmarks.landmark[23].y * image_height\n",
        "    left_shoulder_y = results.pose_landmarks.landmark[11].y * image_height\n",
        "\n",
        "    right_index_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_INDEX].y * image_height\n",
        "    right_pinky_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_PINKY].y * image_height\n",
        "    right_thumb_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_THUMB].y * image_height\n",
        "    right_wrist_y = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST].y * image_height\n",
        "    right_elbow_y = results.pose_landmarks.landmark[14].y * image_height\n",
        "    right_hip_y = results.pose_landmarks.landmark[24].y * image_height\n",
        "    right_shoulder_y = results.pose_landmarks.landmark[12].y * image_height\n",
        "\n",
        "    if(left_elbow_y > left_shoulder_y and left_wrist_y > left_shoulder_y):\n",
        "      b1 = False\n",
        "    if(right_elbow_y > right_shoulder_y and right_wrist_y > right_shoulder_y):\n",
        "      b2 = False\n",
        "\n",
        "    if(left_elbow_y < left_shoulder_y and left_wrist_y < left_shoulder_y):\n",
        "      if((not b1) and (not b2)):\n",
        "        b1 = True\n",
        "        if(not(abs(right_elbow_y-right_shoulder_y) < (image_height//20))):\n",
        "          counter_one_hand += 1\n",
        "\n",
        "    if(right_elbow_y < right_shoulder_y and right_wrist_y < right_shoulder_y):\n",
        "      if((not b1) and (not b2)):\n",
        "        b2 = True\n",
        "        if(not(abs(left_elbow_y-left_shoulder_y) < (image_height//20))):\n",
        "          counter_one_hand += 1\n",
        "    \n",
        "    ###############################################################################\n",
        "\n",
        "    left_leg = [results.pose_world_landmarks.landmark[i] for i in [23, 25, 29]]\n",
        "    right_leg = [results.pose_world_landmarks.landmark[i]\n",
        "                 for i in [24, 26, 30]]\n",
        "\n",
        "    leftLegAngle = getLegAngle(left_leg)\n",
        "    rightLegAngle = getLegAngle(right_leg)\n",
        "\n",
        "    if leftLegAngle <= 100 and rightLegAngle <= 100:\n",
        "        currPosition = 2\n",
        "        if state == 1:\n",
        "            counter_squats += 1\n",
        "        state = 2\n",
        "    elif leftLegAngle >= 140 and rightLegAngle >= 140:\n",
        "        currPosition = 0\n",
        "        state = 0\n",
        "    elif leftLegAngle <= 140 and rightLegAngle <= 140:\n",
        "        currPosition = 1\n",
        "        if state == 0:\n",
        "            state = 1\n",
        "    else:\n",
        "        currPosition = -1\n",
        "    position = currPosition\n",
        "\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "    image = cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "    #print(image.shape)\n",
        "\n",
        "    outp = \"One hand raises = \"+str(counter_one_hand)\n",
        "    image = cv2.rectangle(image, (5, 10), (185, 40), (255, 255, 255), -1)\n",
        "    image = cv2.putText(image, outp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    \n",
        "    outp1 = \"Both hand raises = \"+str(counter_both_hands)\n",
        "    image = cv2.rectangle(\n",
        "        image, (5, 50), (190, 80), (255, 255, 255), -1)\n",
        "    cv2.putText(image, outp1, (10, 70),cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "    \n",
        "    # SQUATS TEXT\n",
        "    outp2 = \"Squats = \"+str(counter_squats)\n",
        "    image = cv2.rectangle(\n",
        "        image, (image_width-115, 10), (image_width-5, 40), (255, 255, 255), -1)\n",
        "    cv2.putText(image, outp2, (image_width-105, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    outp3 = \"Bicep_curls = \"+str(counter_bicep_curl)\n",
        "    image = cv2.rectangle(\n",
        "        image, (image_width-145, 50), (image_width-5, 80), (255, 255, 255), -1)\n",
        "    cv2.putText(image, outp3, (image_width-135, 70), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    #cv2.imshow('MediaPipe Pose',image)\n",
        "    frames.append(image)\n",
        "    #if cv2.waitKey(5) & 0xFF == 27:\n",
        "        #break\n",
        "\n",
        "  height, width, depth = frames[0].shape\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  annotated_video = cv2.VideoWriter('/content/annotated_video.mp4', fourcc, 30, (width, height))\n",
        "\n",
        "  for i in range(len(frames)):\n",
        "      annotated_video.write(frames[i])\n",
        "\n",
        "print(\"frames\",len(frames))\n",
        "\n",
        "print(\"Both hands\", counter_both_hands)\n",
        "print(\"One hand\", counter_one_hand)\n",
        "print(\"Squats\", counter_squats)\n",
        "print(\"bicep curl\", counter_bicep_curl)\n",
        "\n",
        "cap.release()\n",
        "annotated_video.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ApEmm7lsVxV",
        "outputId": "49b89e7d-c5f5-4082-daf1-b6e8af84b3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring empty camera frame.\n",
            "frames 1087\n",
            "Both hands 2\n",
            "One hand 0\n",
            "Squats 3\n",
            "bicep curl 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qSr7MXCTJbbb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}